## NEAT Prescriptor

This example implements the prescription API using NEAT.
This example will not achieve high performance out-of-the-box.

The goal of this example is to provide an example of how the various
scaffolding can fit together to produce a valid prescriptor.

In particular, the prescriptor uses the input historical IPs file,
the input weights file, along with historical case data to make prescriptions.

This example is unoptimized.
For example, it uses default NEAT parameters,
uses a naiive fitness function,
and provides no method for selecting a tradeoff of evolved solutions.

It also uses a computationally inefficient method of iteratively calling the predictor
that scales quadratically with the number of calls.

### Setup

These assume the `covid-xprize` repo is located at `<workspace>/covid-xprize`.

If you have not already done so, install requirements, which include neat-python:
```
cd <workspace>/covid-xprize
pip install -r requirements.txt
```

Ensure that `covid-xprize` is in your PYTHONPATH:
```
export PYTHONPATH=$PYTHONPATH:<workspace>/covid-xprize/
```

### Training Prescriptors

The script `train_prescriptors.py` gives an example of how to train prescriptors.
Here's how it's used:
```
cd <workspace>/covid-xprize/covid_xprize/examples/prescriptors/neat/
python train_prescriptors.py
```
Periodically, this script saves the current population to `neat-checkpoint-*`.
These saved networks can then be used in prescriptor submissions.

There are MANY ways to improve `train_prescriptors.py`.
See the comments in the file for some example directions for improvement.

The script configures neat-python using the file `config-prescriptor`.
This file contains many options for the underlying algorithm.



### Prescribing with trained Prescriptors

The script `prescribe.py` implements the API required for prescriptor submissions.

As is, it simply loads one of the checkpoints from training,
and makes prescriptions with each network in that checkpoint.

Say we would like to prescribe using the checkpoint `neat-checkpoint-4`.
Then, open `prescribe.py` and change the line defining `PRESCRIPTORS_FILE` to
```
PRESCRIPTORS_FILE = 'neat-checkpoint-4'
```

Then, prescriptions can be generated by following the API.
For example, say we would like to generate predictions from August 1st to 5th,
and store the results in `test_prescriptions.csv`:
```
cd <workspace>/covid-xprize/covid_xprize/examples/prescriptors/neat/
python prescribe.py --start_date 2020-08-01 --end_date 2020-08-05 -ip ../../../validation/data/2020-09-30_historical_ip.csv -c ../../../validation/data/uniform_random_costs.csv -o test_prescriptions.csv
```

In general, it will be more useful to assemble a set of prescriptors for submission
in a more discerning way, and store and load them in a different way as well.

See the constants defined at the top of `prescribe.py` for other parameters that can be adjusted.


### Evaluating prescription performance

Once prescriptions are generated, different prescriptions for the same sets of geos and days
can be compared using the notebook `<workspace>/covid-xprize/prescriptor_robojudge.ipynb`:
```
cd <workspace>/covid-xprize/
jupyter notebook prescriptor_robojudge.ipynb
```

