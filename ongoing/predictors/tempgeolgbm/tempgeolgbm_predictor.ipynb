{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses a learnable embedding for the countries which is fed as input to both encoders (at the respective dense layers).\n",
    "\n",
    "# Copyright 2020 (c) Cognizant Digital Business, Evolutionary AI. All rights reserved. Issued under the Apache 2.0 License.\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import pickle\n",
    "from sklearn.multioutput import MultiOutputRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ongoing.predictors.base as base\n",
    "from ongoing.predictors.base import BasePredictor\n",
    "\n",
    "# See https://github.com/OxCGRT/covid-policy-tracker\n",
    "DATA_URL = \"https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"\" when run in command line\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "ROOT_DIR = \"/home/thinng/code/2020/covid-xprize/ongoing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(ROOT_DIR, 'data')\n",
    "MODEL_FILE = os.path.join(ROOT_DIR, 'predictors/tempgeolgbm/models/model.pkl')\n",
    "\n",
    "TEMPERATURE_DATA_FILE_PATH = os.path.join(DATA_PATH, \"temperature_data.csv\")\n",
    "TEMPERATURE_COLUMN = 'temp,C'\n",
    "HOLIDAY_COLUMN = 'Holiday'\n",
    "\n",
    "NB_LOOKBACK_DAYS = 21\n",
    "NB_TEST_DAYS = 14\n",
    "WINDOW_SIZE = 7\n",
    "US_PREFIX = \"United States / \"\n",
    "NPI_DELAY = 0\n",
    "TEMP_SCALE = 20.  # divide temperature values by 20 so they're roughly in the range 0-2\n",
    "AVG_EARTH_TEMP = 16./TEMP_SCALE  # average temperature on earth (used to predict for locations where temperature data is missing)\n",
    "\n",
    "HYPOTHETICAL_SUBMISSION_DATE = np.datetime64(\"2020-05-06\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/thinng/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: wheel in /home/thinng/.local/lib/python3.7/site-packages (from lightgbm) (0.33.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/thinng/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: scipy in /home/thinng/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: numpy in /home/thinng/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages (from lightgbm) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/thinng/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: scipy in /home/thinng/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: numpy in /home/thinng/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages (from lightgbm) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/thinng/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "Requirement already satisfied: numpy in /home/thinng/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages (from lightgbm) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'subsample': 0.5,\n",
    "    'subsample_freq': 1,\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 2 ** 5 - 1,\n",
    "    'min_data_in_leaf': 2 ** 6 - 1,\n",
    "    'feature_fraction': 0.5,\n",
    "    'max_bin': 100,\n",
    "    'n_estimators': 1000,\n",
    "    'boost_from_average': False,\n",
    "    'verbose': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test: Nov\n",
      "Using existing data up to date 2020-12-10\n",
      "Training on data from 2020-01-11 up to 2020-10-31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "Testing on data from 2020-11-01 up to 2020-11-30\n",
      "WARNING: No temperature data available for Bahamas\n",
      "WARNING: No temperature data available for Bermuda\n",
      "WARNING: No temperature data available for Brazil / Acre\n",
      "WARNING: No temperature data available for Brazil / Alagoas\n",
      "WARNING: No temperature data available for Brazil / Amazonas\n",
      "WARNING: No temperature data available for Brazil / Amapa\n",
      "WARNING: No temperature data available for Brazil / Bahia\n",
      "WARNING: No temperature data available for Brazil / Ceara\n",
      "WARNING: No temperature data available for Brazil / Distrito Federal\n",
      "WARNING: No temperature data available for Brazil / Espirito Santo\n",
      "WARNING: No temperature data available for Brazil / Goias\n",
      "WARNING: No temperature data available for Brazil / Maranhao\n",
      "WARNING: No temperature data available for Brazil / Minas Gerais\n",
      "WARNING: No temperature data available for Brazil / Mato Grosso do Sul\n",
      "WARNING: No temperature data available for Brazil / Mato Grosso\n",
      "WARNING: No temperature data available for Brazil / Para\n",
      "WARNING: No temperature data available for Brazil / Paraiba\n",
      "WARNING: No temperature data available for Brazil / Pernambuco\n",
      "WARNING: No temperature data available for Brazil / Piaui\n",
      "WARNING: No temperature data available for Brazil / Parana\n",
      "WARNING: No temperature data available for Brazil / Rio de Janeiro\n",
      "WARNING: No temperature data available for Brazil / Rio Grande do Norte\n",
      "WARNING: No temperature data available for Brazil / Rondonia\n",
      "WARNING: No temperature data available for Brazil / Roraima\n",
      "WARNING: No temperature data available for Brazil / Rio Grande do Sul\n",
      "WARNING: No temperature data available for Brazil / Santa Catarina\n",
      "WARNING: No temperature data available for Brazil / Sergipe\n",
      "WARNING: No temperature data available for Brazil / Sao Paulo\n",
      "WARNING: No temperature data available for Brazil / Tocantins\n",
      "WARNING: No temperature data available for Cape Verde\n",
      "WARNING: No temperature data available for Faeroe Islands\n",
      "WARNING: No temperature data available for United Kingdom / England\n",
      "WARNING: No temperature data available for United Kingdom / Northern Ireland\n",
      "WARNING: No temperature data available for United Kingdom / Scotland\n",
      "WARNING: No temperature data available for United Kingdom / Wales\n",
      "WARNING: No temperature data available for Greenland\n",
      "WARNING: No temperature data available for Monaco\n",
      "WARNING: No temperature data available for Myanmar\n",
      "WARNING: No temperature data available for Puerto Rico\n",
      "WARNING: No temperature data available for Palestine\n",
      "WARNING: No temperature data available for Eswatini\n",
      "WARNING: No temperature data available for Trinidad and Tobago\n",
      "WARNING: No temperature data available for Bahamas\n",
      "WARNING: No temperature data available for Bermuda\n",
      "WARNING: No temperature data available for Brazil / Acre\n",
      "WARNING: No temperature data available for Brazil / Alagoas\n",
      "WARNING: No temperature data available for Brazil / Amazonas\n",
      "WARNING: No temperature data available for Brazil / Amapa\n",
      "WARNING: No temperature data available for Brazil / Bahia\n",
      "WARNING: No temperature data available for Brazil / Ceara\n",
      "WARNING: No temperature data available for Brazil / Distrito Federal\n",
      "WARNING: No temperature data available for Brazil / Espirito Santo\n",
      "WARNING: No temperature data available for Brazil / Goias\n",
      "WARNING: No temperature data available for Brazil / Maranhao\n",
      "WARNING: No temperature data available for Brazil / Minas Gerais\n",
      "WARNING: No temperature data available for Brazil / Mato Grosso do Sul\n",
      "WARNING: No temperature data available for Brazil / Mato Grosso\n",
      "WARNING: No temperature data available for Brazil / Para\n",
      "WARNING: No temperature data available for Brazil / Paraiba\n",
      "WARNING: No temperature data available for Brazil / Pernambuco\n",
      "WARNING: No temperature data available for Brazil / Piaui\n",
      "WARNING: No temperature data available for Brazil / Parana\n",
      "WARNING: No temperature data available for Brazil / Rio de Janeiro\n",
      "WARNING: No temperature data available for Brazil / Rio Grande do Norte\n",
      "WARNING: No temperature data available for Brazil / Rondonia\n",
      "WARNING: No temperature data available for Brazil / Roraima\n",
      "WARNING: No temperature data available for Brazil / Rio Grande do Sul\n",
      "WARNING: No temperature data available for Brazil / Santa Catarina\n",
      "WARNING: No temperature data available for Brazil / Sergipe\n",
      "WARNING: No temperature data available for Brazil / Sao Paulo\n",
      "WARNING: No temperature data available for Brazil / Tocantins\n",
      "WARNING: No temperature data available for Cape Verde\n",
      "WARNING: No temperature data available for Faeroe Islands\n",
      "WARNING: No temperature data available for United Kingdom / England\n",
      "WARNING: No temperature data available for United Kingdom / Northern Ireland\n",
      "WARNING: No temperature data available for United Kingdom / Scotland\n",
      "WARNING: No temperature data available for United Kingdom / Wales\n",
      "WARNING: No temperature data available for Greenland\n",
      "WARNING: No temperature data available for Monaco\n",
      "WARNING: No temperature data available for Myanmar\n",
      "WARNING: No temperature data available for Puerto Rico\n",
      "WARNING: No temperature data available for Palestine\n",
      "WARNING: No temperature data available for Eswatini\n",
      "WARNING: No temperature data available for Trinidad and Tobago\n",
      "Running test: Oct-Nov\n",
      "Using existing data up to date 2020-12-10\n",
      "Training on data from 2020-01-11 up to 2020-09-30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "Testing on data from 2020-10-01 up to 2020-11-30\n",
      "WARNING: No temperature data available for Bahamas\n",
      "WARNING: No temperature data available for Bermuda\n",
      "WARNING: No temperature data available for Brazil / Acre\n",
      "WARNING: No temperature data available for Brazil / Alagoas\n",
      "WARNING: No temperature data available for Brazil / Amazonas\n",
      "WARNING: No temperature data available for Brazil / Amapa\n",
      "WARNING: No temperature data available for Brazil / Bahia\n",
      "WARNING: No temperature data available for Brazil / Ceara\n",
      "WARNING: No temperature data available for Brazil / Distrito Federal\n",
      "WARNING: No temperature data available for Brazil / Espirito Santo\n",
      "WARNING: No temperature data available for Brazil / Goias\n",
      "WARNING: No temperature data available for Brazil / Maranhao\n",
      "WARNING: No temperature data available for Brazil / Minas Gerais\n",
      "WARNING: No temperature data available for Brazil / Mato Grosso do Sul\n",
      "WARNING: No temperature data available for Brazil / Mato Grosso\n",
      "WARNING: No temperature data available for Brazil / Para\n",
      "WARNING: No temperature data available for Brazil / Paraiba\n",
      "WARNING: No temperature data available for Brazil / Pernambuco\n",
      "WARNING: No temperature data available for Brazil / Piaui\n",
      "WARNING: No temperature data available for Brazil / Parana\n",
      "WARNING: No temperature data available for Brazil / Rio de Janeiro\n",
      "WARNING: No temperature data available for Brazil / Rio Grande do Norte\n",
      "WARNING: No temperature data available for Brazil / Rondonia\n",
      "WARNING: No temperature data available for Brazil / Roraima\n",
      "WARNING: No temperature data available for Brazil / Rio Grande do Sul\n",
      "WARNING: No temperature data available for Brazil / Santa Catarina\n",
      "WARNING: No temperature data available for Brazil / Sergipe\n",
      "WARNING: No temperature data available for Brazil / Sao Paulo\n",
      "WARNING: No temperature data available for Brazil / Tocantins\n",
      "WARNING: No temperature data available for Cape Verde\n",
      "WARNING: No temperature data available for Faeroe Islands\n",
      "WARNING: No temperature data available for United Kingdom / England\n",
      "WARNING: No temperature data available for United Kingdom / Northern Ireland\n",
      "WARNING: No temperature data available for United Kingdom / Scotland\n",
      "WARNING: No temperature data available for United Kingdom / Wales\n",
      "WARNING: No temperature data available for Greenland\n",
      "WARNING: No temperature data available for Monaco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No temperature data available for Myanmar\n",
      "WARNING: No temperature data available for Puerto Rico\n",
      "WARNING: No temperature data available for Palestine\n",
      "WARNING: No temperature data available for Eswatini\n",
      "WARNING: No temperature data available for Trinidad and Tobago\n",
      "WARNING: No temperature data available for Bahamas\n",
      "WARNING: No temperature data available for Bermuda\n",
      "WARNING: No temperature data available for Brazil / Acre\n",
      "WARNING: No temperature data available for Brazil / Alagoas\n",
      "WARNING: No temperature data available for Brazil / Amazonas\n",
      "WARNING: No temperature data available for Brazil / Amapa\n",
      "WARNING: No temperature data available for Brazil / Bahia\n",
      "WARNING: No temperature data available for Brazil / Ceara\n",
      "WARNING: No temperature data available for Brazil / Distrito Federal\n",
      "WARNING: No temperature data available for Brazil / Espirito Santo\n",
      "WARNING: No temperature data available for Brazil / Goias\n",
      "WARNING: No temperature data available for Brazil / Maranhao\n",
      "WARNING: No temperature data available for Brazil / Minas Gerais\n",
      "WARNING: No temperature data available for Brazil / Mato Grosso do Sul\n",
      "WARNING: No temperature data available for Brazil / Mato Grosso\n",
      "WARNING: No temperature data available for Brazil / Para\n",
      "WARNING: No temperature data available for Brazil / Paraiba\n",
      "WARNING: No temperature data available for Brazil / Pernambuco\n",
      "WARNING: No temperature data available for Brazil / Piaui\n",
      "WARNING: No temperature data available for Brazil / Parana\n",
      "WARNING: No temperature data available for Brazil / Rio de Janeiro\n",
      "WARNING: No temperature data available for Brazil / Rio Grande do Norte\n",
      "WARNING: No temperature data available for Brazil / Rondonia\n",
      "WARNING: No temperature data available for Brazil / Roraima\n",
      "WARNING: No temperature data available for Brazil / Rio Grande do Sul\n",
      "WARNING: No temperature data available for Brazil / Santa Catarina\n",
      "WARNING: No temperature data available for Brazil / Sergipe\n",
      "WARNING: No temperature data available for Brazil / Sao Paulo\n",
      "WARNING: No temperature data available for Brazil / Tocantins\n",
      "WARNING: No temperature data available for Cape Verde\n",
      "WARNING: No temperature data available for Faeroe Islands\n",
      "WARNING: No temperature data available for United Kingdom / England\n",
      "WARNING: No temperature data available for United Kingdom / Northern Ireland\n",
      "WARNING: No temperature data available for United Kingdom / Scotland\n",
      "WARNING: No temperature data available for United Kingdom / Wales\n",
      "WARNING: No temperature data available for Greenland\n",
      "WARNING: No temperature data available for Monaco\n",
      "WARNING: No temperature data available for Myanmar\n",
      "WARNING: No temperature data available for Puerto Rico\n",
      "WARNING: No temperature data available for Palestine\n",
      "WARNING: No temperature data available for Eswatini\n",
      "WARNING: No temperature data available for Trinidad and Tobago\n",
      "Running test: Sep-Nov\n",
      "Using existing data up to date 2020-12-10\n",
      "Training on data from 2020-01-11 up to 2020-08-31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6ca592dd2cca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempGeoLGBMPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/2020/covid-xprize/ongoing/predictors/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training on data from {} up to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6ca592dd2cca>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiOutputRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 **fit_params_validated)\n\u001b[0;32m--> 176\u001b[0;31m             for i in range(y.shape[1]))\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    777\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                                        callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    615\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                               callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xprize_env_37/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2458\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2459\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2460\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2461\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class tempGeoLGBMPredictor(BasePredictor):\n",
    "    \"\"\"\n",
    "    A class that computes a fitness for Prescriptor candidates.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 nb_lookback_days=NB_LOOKBACK_DAYS,\n",
    "                 nb_test_days=NB_TEST_DAYS, window_size=WINDOW_SIZE, npi_delay=NPI_DELAY,\n",
    "                 seed=base.SEED):\n",
    "\n",
    "        super().__init__(seed=seed)\n",
    "        self.nb_lookback_days = nb_lookback_days\n",
    "        self.nb_test_days = nb_test_days\n",
    "        self.window_size = window_size\n",
    "        self.npi_delay = npi_delay\n",
    "\n",
    "        # read and preprocess temperature data\n",
    "        self.temp_df = pd.read_csv(TEMPERATURE_DATA_FILE_PATH,\n",
    "                                   parse_dates=['Date'],\n",
    "                                   encoding=\"ISO-8859-1\",\n",
    "                                   dtype={\"RegionName\": str,\n",
    "                                          \"RegionCode\": str},\n",
    "                                   error_bad_lines=False)\n",
    "        self.temp_df[\"GeoID\"] = np.where(self.temp_df[\"RegionName\"].isnull(),\n",
    "                                         self.temp_df[\"CountryName\"],\n",
    "                                         self.temp_df[\"CountryName\"] + ' / ' + self.temp_df[\"RegionName\"])\n",
    "        self.temp_df[TEMPERATURE_COLUMN] = self.temp_df[TEMPERATURE_COLUMN]/TEMP_SCALE\n",
    "\n",
    "        self.country_samples = None  # will be set when fit() or predict() are called\n",
    "\n",
    "    def predict(self, data=None, start_date=None, end_date=None):\n",
    "        if self.train_df is None:\n",
    "            raise Exception(\"train_df must be defined before calling predict()\")\n",
    "\n",
    "        if data is None:\n",
    "            data = self.test_df\n",
    "        if start_date is None:\n",
    "            start_date = pd.to_datetime(data.Date.min(), format='%Y-%m-%d')\n",
    "        if end_date is None:\n",
    "            end_date = pd.to_datetime(data.Date.max(), format='%Y-%m-%d')\n",
    "\n",
    "        train_df = pd.merge(self.train_df, self.temp_df, on=['CountryName', 'RegionName', 'GeoID', 'Date'], how='left')\n",
    "        train_df[TEMPERATURE_COLUMN] = train_df[TEMPERATURE_COLUMN].fillna(AVG_EARTH_TEMP)\n",
    "        train_df[HOLIDAY_COLUMN] = train_df[HOLIDAY_COLUMN].fillna(0)\n",
    "        self.country_samples = self._create_country_samples(train_df,\n",
    "                                                            list(self.train_df.GeoID.unique()),\n",
    "                                                            self.nb_lookback_days,\n",
    "                                                            self.npi_delay,\n",
    "                                                            self.nb_test_days)\n",
    "\n",
    "        nb_days = (end_date - start_date).days + 1\n",
    "\n",
    "        # Prepare the output\n",
    "        forecast = {\"GeoID\": [],\n",
    "                    \"CountryName\": [],\n",
    "                    \"RegionName\": [],\n",
    "                    \"Date\": [],\n",
    "                    \"PredictedDailyTotalCases\": [],\n",
    "                    \"PredictedDailyNewCases\": [],\n",
    "                    \"PredictedDailyTotalDeaths\": [],\n",
    "                    \"PredictedDailyNewDeaths\": []}\n",
    "\n",
    "        # For each requested geo\n",
    "        geos = data.GeoID.unique()\n",
    "        for g in geos:\n",
    "            cdf = self.train_df[self.train_df.GeoID == g]\n",
    "\n",
    "            if len(cdf) == 0:\n",
    "                # we don't have historical data for this geo: return zeroes\n",
    "                print(\"WARNING: No historical data for {}\".format(g))\n",
    "                pred_total_cases = [0] * nb_days\n",
    "                pred_new_cases = [0] * nb_days\n",
    "                pred_total_deaths = [0] * nb_days\n",
    "                pred_new_deaths = [0] * nb_days\n",
    "                geo_start_date = start_date\n",
    "            else:\n",
    "                last_known_date = cdf.Date.max()\n",
    "                # Start predicting from start_date, unless there's a gap since last known date\n",
    "                geo_start_date = min(last_known_date + np.timedelta64(1, 'D'), start_date)\n",
    "                npis_gdf = data[(data.Date >= geo_start_date - pd.Timedelta(days=self.npi_delay)) & (data.Date <= end_date - pd.Timedelta(days=self.npi_delay))]\n",
    "                temp_gdf = self.temp_df[(self.temp_df.Date >= geo_start_date.replace(year=2020)) & (self.temp_df.Date <= end_date.replace(year=2020))]\n",
    "                # if temp_gdf.empty:\n",
    "                #     print(\"WARNING: No temperature data available for {} ({} - {})\".format(g, geo_start_date.replace(year=2020).strftime(\"%Y/%m/%d\"), end_date.replace(year=2020).strftime(\"%Y/%m/%d\")))\n",
    "                #     temp_gdf = pd.DataFrame.from_dict({TEMPERATURE_COLUMN: AVG_EARTH_TEMP*np.ones((end_date-geo_start_date).days),\n",
    "                #                                        HOLIDAY_COLUMN: np.zeros(((end_date-geo_start_date).days))})\n",
    "                pred_total_cases, pred_new_cases, pred_total_deaths, pred_new_deaths = self._get_new_cases_preds(cdf, g, npis_gdf, temp_gdf)\n",
    "\n",
    "            # Append forecast data to results to return\n",
    "            country = data[data.GeoID == g].iloc[0].CountryName\n",
    "            region = data[data.GeoID == g].iloc[0].RegionName\n",
    "            for i, (ptot_cases, pnew_cases, ptot_deaths, pnew_deaths) in enumerate(zip(pred_total_cases, pred_new_cases, pred_total_deaths, pred_new_deaths)):\n",
    "                forecast[\"GeoID\"].append(g)\n",
    "                forecast[\"CountryName\"].append(country)\n",
    "                forecast[\"RegionName\"].append(region)\n",
    "                current_date = geo_start_date + pd.offsets.Day(i)\n",
    "                forecast[\"Date\"].append(current_date)\n",
    "                forecast[\"PredictedDailyTotalCases\"].append(ptot_cases)\n",
    "                forecast[\"PredictedDailyNewCases\"].append(pnew_cases)\n",
    "                forecast[\"PredictedDailyTotalDeaths\"].append(ptot_deaths)\n",
    "                forecast[\"PredictedDailyNewDeaths\"].append(pnew_deaths)\n",
    "\n",
    "        forecast_df = pd.DataFrame.from_dict(forecast)\n",
    "        # Return only the requested predictions\n",
    "        return forecast_df[(forecast_df.Date >= start_date) & (forecast_df.Date <= end_date)]\n",
    "\n",
    "    def _get_new_cases_preds(self, c_df, g, npis_df, temp_df):\n",
    "        cdf = c_df[c_df.ConfirmedCases.notnull()]\n",
    "        initial_context_input = self.country_samples[g]['X_test_context'][-1]\n",
    "        initial_action_input = self.country_samples[g]['X_test_action'][-1]\n",
    "        # Predictions with passed npis\n",
    "        cnpis_df = npis_df[npis_df.GeoID == g]\n",
    "        npis_sequence = np.array(cnpis_df[base.NPI_COLUMNS])\n",
    "        ctemp_df = temp_df[temp_df.GeoID == g]\n",
    "        if ctemp_df.empty:\n",
    "            print(\"WARNING: No temperature data available for {}\".format(g))\n",
    "            temp_sequence = AVG_EARTH_TEMP*np.ones(npis_sequence.shape[0])\n",
    "            holiday_sequence = np.zeros(npis_sequence.shape[0])\n",
    "        else:\n",
    "            temp_sequence = np.array(ctemp_df[TEMPERATURE_COLUMN])\n",
    "            holiday_sequence = np.array(ctemp_df[HOLIDAY_COLUMN])\n",
    "        # Get the predictions with the passed NPIs\n",
    "        preds = self._roll_out_predictions(self.predictor,\n",
    "                                           initial_context_input,\n",
    "                                           initial_action_input,\n",
    "                                           npis_sequence,\n",
    "                                           temp_sequence,\n",
    "                                           holiday_sequence)\n",
    "        preds_cases = preds[:,0]\n",
    "        preds_deaths = preds[:,1]\n",
    "        # Gather info to convert to total cases\n",
    "        prev_confirmed_cases = np.array(cdf.ConfirmedCases)\n",
    "        prev_new_cases = np.array(cdf.NewCases)\n",
    "        initial_total_cases = prev_confirmed_cases[-1]\n",
    "        pop_size = np.array(cdf.Population)[-1]  # Population size doesn't change over time\n",
    "        prev_confirmed_deaths = np.array(cdf.ConfirmedDeaths)\n",
    "        prev_new_deaths = np.array(cdf.NewDeaths)\n",
    "        initial_total_deaths = prev_confirmed_deaths[-1]\n",
    "\n",
    "        # Compute predictor's forecast\n",
    "        pred_total_cases, pred_new_cases = base.convert_ratios_to_total_cases(\n",
    "            preds_cases,\n",
    "            self.window_size,\n",
    "            prev_new_cases,\n",
    "            initial_total_cases,\n",
    "            pop_size)\n",
    "\n",
    "        # Compute predictor's deaths forecast\n",
    "        pred_total_deaths, pred_new_deaths = base.convert_ratios_to_total_deaths(\n",
    "            preds_deaths,\n",
    "            self.window_size,\n",
    "            prev_new_deaths,\n",
    "            initial_total_deaths)\n",
    "\n",
    "        return pred_total_cases, pred_new_cases, pred_total_deaths, pred_new_deaths\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_country_samples(df: pd.DataFrame, geos: list, nb_lookback_days: int, npi_delay: int, nb_test_days: int) -> dict:\n",
    "        \"\"\"\n",
    "        For each country, creates numpy arrays for Keras\n",
    "        :param df: a Pandas DataFrame with historical data for countries (the \"Oxford\" dataset)\n",
    "        :param geos: a list of geo names\n",
    "        :return: a dictionary of train and test sets, for each specified country\n",
    "        \"\"\"\n",
    "        context_column = ['PredictionRatio', 'DeathRatio', TEMPERATURE_COLUMN, HOLIDAY_COLUMN]\n",
    "        action_columns = base.NPI_COLUMNS\n",
    "        outcome_column = ['PredictionRatio', 'DeathRatio']\n",
    "        country_samples = {}\n",
    "        for i, g in enumerate(geos):\n",
    "            cdf = df[df.GeoID == g]\n",
    "            cdf = cdf[cdf.ConfirmedCases.notnull()]\n",
    "            context_data = np.array(cdf[context_column])\n",
    "            action_data = np.array(cdf[action_columns])\n",
    "            outcome_data = np.array(cdf[outcome_column])\n",
    "            context_samples = []\n",
    "            action_samples = []\n",
    "            outcome_samples = []\n",
    "            nb_total_days = outcome_data.shape[0]\n",
    "            for d in range(nb_lookback_days+npi_delay, nb_total_days):\n",
    "                context_samples.append(context_data[d - nb_lookback_days: d])\n",
    "                action_samples.append(action_data[d-npi_delay - nb_lookback_days: d-npi_delay])\n",
    "                outcome_samples.append(outcome_data[d])\n",
    "            if len(outcome_samples) > 0:\n",
    "                X_context = np.stack(context_samples, axis=0)\n",
    "                X_action = np.stack(action_samples, axis=0)\n",
    "                X_country = i*np.ones(X_context.shape[0])\n",
    "                y = np.stack(outcome_samples, axis=0)\n",
    "                country_samples[g] = {\n",
    "                    'X_context': X_context,\n",
    "                    'X_action': X_action,\n",
    "                    'X_country': X_country,\n",
    "                    'y': y,\n",
    "                    'X_test_context': X_context[-nb_test_days:],\n",
    "                    'X_test_action': X_action[-nb_test_days:],\n",
    "                    'X_test_country': X_country[-nb_test_days:],\n",
    "                    'y_test': y[-nb_test_days:],\n",
    "                }\n",
    "        return country_samples\n",
    "\n",
    "    # Function for performing roll outs into the future\n",
    "    def _roll_out_predictions(self, predictor, initial_context_input, initial_action_input,future_action_sequence, future_temperature_sequence, future_holiday_sequence):\n",
    "        nb_roll_out_days = future_action_sequence.shape[0]\n",
    "        pred_output = np.zeros((nb_roll_out_days, 2))\n",
    "        context_input = np.expand_dims(np.copy(initial_context_input), axis=0)\n",
    "        action_input = np.expand_dims(np.copy(initial_action_input), axis=0)\n",
    "        for d in range(nb_roll_out_days):\n",
    "            action_input[:, :-1] = action_input[:, 1:]\n",
    "            # Use the passed actions\n",
    "            action_sequence = future_action_sequence[d]\n",
    "            action_input[:, -1] = action_sequence\n",
    "#             inputs = [context_input, action_input]\n",
    "            inputs = np.concatenate((context_input.reshape((context_input.shape[0],-1)), action_input.reshape((action_input.shape[0],-1))), axis=1)\n",
    "            pred = predictor.predict(inputs)\n",
    "            pred_output[d] = pred[-1]\n",
    "            context_input[:, :-1] = context_input[:, 1:]\n",
    "            context_input[:, -1, 0:2] = pred[-1]\n",
    "            context_input[:, -1, 2] = future_temperature_sequence[d]\n",
    "            context_input[:, -1, 3] = future_holiday_sequence[d]\n",
    "        return pred_output\n",
    "\n",
    "    def fit(self):\n",
    "        if self.train_df is None:\n",
    "            raise Exception(\"train_df must be defined bfr calling predict()\")\n",
    "\n",
    "        # merge the two dataframes (keep only rows where new cases rate and temperature are available)\n",
    "        train_df = pd.merge(self.train_df, self.temp_df, on=['CountryName', 'RegionName', 'GeoID', 'Date'], how='inner')\n",
    "        self.country_samples = self._create_country_samples(train_df,\n",
    "                                                            list(train_df.GeoID.unique()),\n",
    "                                                            self.nb_lookback_days,\n",
    "                                                            self.npi_delay,\n",
    "                                                            self.nb_test_days)\n",
    "        self.geos = list(self.country_samples.keys())\n",
    "\n",
    "        # Aggregate data for training\n",
    "        all_X_context_list = [self.country_samples[c]['X_context']\n",
    "                              for c in self.country_samples]\n",
    "        all_X_action_list = [self.country_samples[c]['X_action']\n",
    "                             for c in self.country_samples]\n",
    "        all_X_country_list = [self.country_samples[c]['X_country']\n",
    "                              for c in self.country_samples]\n",
    "        all_y_list = [self.country_samples[c]['y']\n",
    "                      for c in self.country_samples]\n",
    "        X_context = np.concatenate(all_X_context_list)\n",
    "        X_action = np.concatenate(all_X_action_list)\n",
    "        X_country = np.concatenate(all_X_country_list)\n",
    "        y = np.concatenate(all_y_list)\n",
    "\n",
    "        # Clip outliers\n",
    "        MIN_VALUE = 0.\n",
    "        MAX_VALUE = 2.\n",
    "        X_context = np.clip(X_context, MIN_VALUE, MAX_VALUE)\n",
    "        y = np.clip(y, MIN_VALUE, MAX_VALUE)\n",
    "        \n",
    "        X = np.concatenate((X_context.reshape((X_context.shape[0],-1)), X_action.reshape((X_action.shape[0],-1))), axis=1)\n",
    "        model = MultiOutputRegressor(lgb.LGBMRegressor(**params))\n",
    "        model.fit(X, y)\n",
    "\n",
    "\n",
    "        with open(MODEL_FILE, 'wb') as model_file:\n",
    "            pickle.dump(model, model_file)            \n",
    "\n",
    "        self.predictor = model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = tempGeoLGBMPredictor()\n",
    "    x = model.evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
